{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f91738a1-11d8-4eb2-b14a-be4d3e98323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stable_baselines3\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "# Environement\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "# Evaluate the environement\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy, plot_results\n",
    "\n",
    "# Agent\n",
    "from stable_baselines3 import A2C\n",
    "# Policy\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7957cd36",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'StbBL_Base/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[0;32mIn [85]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m SOLUTION_NAME \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStbBL_Base\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m log_dir \u001b[38;5;241m=\u001b[39m SOLUTION_NAME \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/os.py:223\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'StbBL_Base/'"
     ]
    }
   ],
   "source": [
    "SOLUTION_NAME = \"StbBL_Base\"\n",
    "log_dir = SOLUTION_NAME + \"/\"\n",
    "os.makedirs(log_dir, exist_ok=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123a613c-6f17-4617-8bef-4506218d544e",
   "metadata": {},
   "source": [
    "# Environement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abae2914",
   "metadata": {},
   "source": [
    "## Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cf4bb78c-7432-4d76-b8d5-04d5f63a205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEnv(gym.Env):\n",
    "    \"\"\"Custom Environment that follows gym interface\"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    CASE_VIDE = 255\n",
    "    \n",
    "    def __init__(self, grid_size=(10,10),nspecies=8):\n",
    "        # CONTROLES DONNEES\n",
    "        assert nspecies < 256-1 # pour compatibilité avec uint8. 0 est pris par l'information case vide\n",
    "        \n",
    "        # INITILISATIION SUBCLASS\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        # PARAMETRES \n",
    "        self.grid_size = grid_size\n",
    "        self.nspecies = nspecies\n",
    "\n",
    "        \n",
    "        \n",
    "        # Define action space\n",
    "        # ESSAI 1 : NE MARCHE PAS, CE SONT DES VALEURS CONTINUES MEME AVEC dype\n",
    "#         self.action_space = spaces.Box(low=np.array([0,0,0]),\n",
    "#                                       high=np.array(self.grid_size + (self.nspecies,)),\n",
    "#                                       shape=(3,),\n",
    "#                                       dtype=np.uint8)        \n",
    "        # ESSAI 2 :\n",
    "        self.action_space =spaces.MultiDiscrete(self.grid_size + (self.nspecies,))\n",
    "        \n",
    "        # Define observation space\n",
    "        self.observation_space = spaces.Box(low=0,\n",
    "                                            high=self.nspecies,\n",
    "                                            shape=grid_size, dtype=np.uint8)\n",
    "        \n",
    "        self._state = np.full(self.grid_size,self.CASE_VIDE)\n",
    "    \n",
    "    \n",
    "    def step(self, action):\n",
    "        # ACTION -> ACTION LOCALE\n",
    "        x,y,specie = action\n",
    "        \n",
    "        print(x,y,specie)\n",
    "        \n",
    "        # CONTROLE\n",
    "        assert specie != self.CASE_VIDE\n",
    "        \n",
    "        done = False # JUSQU'A PREUVE DU CONTRAIRE LA PARTIE CONTINUE\n",
    "        info = {} # UTILISE POUR DEBUGAGE\n",
    "        reward = 0\n",
    "        if self._state[x,y]==self.CASE_VIDE:\n",
    "            # ACTION VALIDE (CASE LIBRE) CAR ==0            \n",
    "            self._state[x,y] = specie # ON PLANTE\n",
    "            reward = 1 # <--------------------------------------------------REWARD NON LEGUME\n",
    "            if (self._state[x,y]==self.CASE_VIDE).sum()==0:\n",
    "                # DANS LE CAS ON IL N'Y A PLUS DE CASES VIDES\n",
    "                reward = 100 # <--------------------------------------------------REWARD SUCCESS\n",
    "                done = True \n",
    "            \n",
    "        else:\n",
    "            # ACTION NON VALIDE CASE DEJA REMPLIE\n",
    "            reward = -100 # <--------------------------------------------------REWARD FAIL\n",
    "            done = True\n",
    "            \n",
    "        return self.to_observation(), reward, done, info\n",
    "    \n",
    "    def reset(self):\n",
    "        self._state = np.full(self.grid_size,self.CASE_VIDE) # TODO ESSAYER DE FAIRE UN RANDOM A CHAQUE RESET PLUTOT 0, COMME SUGGERE PAR GUILLAUME\n",
    "        return self.to_observation()\n",
    "    \n",
    "    def to_observation(self):\n",
    "        return self._state.copy()\n",
    "    \n",
    "    def render(self,mode=\"human\"):\n",
    "        return self.to_observation()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8695d2c5",
   "metadata": {},
   "source": [
    "## Instanciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0803f107",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CustomEnv()\n",
    "eval_env = CustomEnv() # Use a separate environement for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b6cfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvWithQuotas(gym.Env):\n",
    "    \"\"\"Custom Environment that follows gym interface\"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, grid_size=(10,10),nspecies=255):\n",
    "        # CONTROLES DONNEES\n",
    "        assert nspecies < 256 # pour compatibilité avec uint8\n",
    "        assert quotas is None or quotas.shape == (nspecies,)\n",
    "        \n",
    "        # INITILISATIION SUBCLASS\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        # PARAMETRES \n",
    "        self.grid_size = grid_size\n",
    "        self.nspecies = nspecies\n",
    "        if self.quotas is None:\n",
    "            self.quotas = np.zeros((nspecies,))\n",
    "\n",
    "        \n",
    "        \n",
    "        # Define action space\n",
    "        #    TODO VERIFIER LE TYPE\n",
    "        self.action_space = spaces.Box(low=np.array([0,0,1]),\n",
    "                                      high=np.array(self.grid_size + (self.nspecies,)),\n",
    "                                      shape=(3,),\n",
    "                                      dtype=np.uint8)        \n",
    "        # Define observation space\n",
    "        self.observation_space = spaces.Box(low=0,\n",
    "                                            high=self.nspecies,\n",
    "                                            shape=grid_size, dtype=np.uint8)\n",
    "        \n",
    "        self.state = np.zeros(self.grid_size)\n",
    "    \n",
    "    \n",
    "    def step(self, action):\n",
    "        # ACTION -> ACTION LOCALE\n",
    "        x,y,specie = action\n",
    "        # CONTROLE\n",
    "        \n",
    "        done = False\n",
    "        if self._state[x,y]==0:\n",
    "            # ACTION VALIDE CASE LIBRE CAR ==0\n",
    "            \n",
    "            self._state[x,y]\n",
    "            \n",
    "        else:\n",
    "            # ACTION NON VALIDE CASE DEJA REMPLIE\n",
    "            reward = -100 # <--------------------------------------------------REWARD FAIL\n",
    "            done = True\n",
    "            \n",
    "\n",
    "        \n",
    "        return self.to_observation(), reward, done, info\n",
    "    \n",
    "    def reset(self):\n",
    "        self._state = np.zeros(self.grid_size) # TODO ESSAYER DE FAIRE UN RANDOM A CHAQUE RESET PLUTOT 0, COMME SUGGERE PAR GUILLAUME\n",
    "        return self.to_observation()\n",
    "    \n",
    "    def to_observation(self):\n",
    "        return self._state.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e436161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array([5,1])!=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4854cd0f-9ec8-4759-ae3c-107d8ade040d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 3., 0., 0., 0., 3., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v,c = np.unique(np.array([5,1]),return_counts=True)\n",
    "remp[v] += 1 \n",
    "remp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6679a7a5-a0ec-443f-8f36-def1a7d5b0e7",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9204df5d-b3e2-4cf1-a5c8-25ef63a9a0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "agent = A2C(MlpPolicy, env, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999c225c-5193-45e2-8b74-77ce4f36dccd",
   "metadata": {},
   "source": [
    "## Evaluate random Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a269e3f-3494-47bd-ae81-a18648ef096e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward:100.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxime/.pyenv/versions/iarchitect/lib/python3.8/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Random Agent, before training\n",
    "mean_reward, std_reward = evaluate_policy(agent, eval_env, n_eval_episodes=100)\n",
    "\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35099588-4b64-4539-acc6-ef5b6bb1fd84",
   "metadata": {},
   "source": [
    "## Train the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6048187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCallBack(BaseCallback):\n",
    "    def __init__(self,log_dir):\n",
    "        super().__init__()\n",
    "        self.log_dir = log_dir\n",
    "        \n",
    "    def _on_step(self) -> bool:\n",
    "        x, y = ts2xy(load_results(self.log_dir), 'timesteps')\n",
    "        print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "be0f6ba6-8938-430d-b4d2-d07159629ca4",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadMonitorResultsError",
     "evalue": "No monitor files of the form *monitor.csv found in StbBL_Base/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLoadMonitorResultsError\u001b[0m                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [91]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the agent for 10000 steps\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMyCallBack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/iarchitect/lib/python3.8/site-packages/stable_baselines3/a2c/a2c.py:191\u001b[0m, in \u001b[0;36mA2C.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    180\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    188\u001b[0m     reset_num_timesteps: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    189\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA2C\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mA2C\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_eval_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_eval_episodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_log_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_log_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/iarchitect/lib/python3.8/site-packages/stable_baselines3/common/on_policy_algorithm.py:250\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    246\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 250\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m continue_training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/iarchitect/lib/python3.8/site-packages/stable_baselines3/common/on_policy_algorithm.py:184\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n\u001b[1;32m    183\u001b[0m callback\u001b[38;5;241m.\u001b[39mupdate_locals(\u001b[38;5;28mlocals\u001b[39m())\n\u001b[0;32m--> 184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_info_buffer(infos)\n",
      "File \u001b[0;32m~/.pyenv/versions/iarchitect/lib/python3.8/site-packages/stable_baselines3/common/callbacks.py:88\u001b[0m, in \u001b[0;36mBaseCallback.on_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# timesteps start at zero\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnum_timesteps\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [90]\u001b[0m, in \u001b[0;36mMyCallBack._on_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_on_step\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m----> 7\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m ts2xy(\u001b[43mload_results\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_dir\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimesteps\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x,y)\n",
      "File \u001b[0;32m~/.pyenv/versions/iarchitect/lib/python3.8/site-packages/stable_baselines3/common/monitor.py:224\u001b[0m, in \u001b[0;36mload_results\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    222\u001b[0m monitor_files \u001b[38;5;241m=\u001b[39m get_monitor_files(path)\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(monitor_files) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LoadMonitorResultsError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo monitor files of the form *\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMonitor\u001b[38;5;241m.\u001b[39mEXT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    225\u001b[0m data_frames, headers \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m monitor_files:\n",
      "\u001b[0;31mLoadMonitorResultsError\u001b[0m: No monitor files of the form *monitor.csv found in StbBL_Base/"
     ]
    }
   ],
   "source": [
    "# Train the agent for 10000 steps\n",
    "agent.learn(total_timesteps=1000,callback=MyCallBack(log_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb921820-fd85-4cfa-b383-259727d71322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained agent\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=100)\n",
    "\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ca0ac4-d6d2-47fc-a085-fd9e05dd762f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b67b0ea8-5fc0-4f86-8b35-b81819765ca9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [77]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m log_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSOLUTION_NAME/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mmakedirs(log_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m plot_results([log_dir], timesteps, results_plotter\u001b[38;5;241m.\u001b[39mX_TIMESTEPS, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTD3 LunarLander\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "plot_results([log_dir], timesteps, results_plotter.X_TIMESTEPS, \"TD3 LunarLander\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3684b93-71f8-4036-894e-c0aeb902ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results([log_dir], timesteps, results_plotter.X_TIMESTEPS, \"TD3 LunarLander\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
