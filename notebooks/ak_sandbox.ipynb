{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e8c3721-093c-4e70-aa07-2afd49118be5",
   "metadata": {},
   "source": [
    "# Stable Baselines Exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f91738a1-11d8-4eb2-b14a-be4d3e98323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stable_baselines3\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "# Environement\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "# Evaluate the environement\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# Agent\n",
    "from stable_baselines3 import A2C\n",
    "# Policy\n",
    "from stable_baselines3.ppo import MlpPolicy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123a613c-6f17-4617-8bef-4506218d544e",
   "metadata": {},
   "source": [
    "## Environement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4bb78c-7432-4d76-b8d5-04d5f63a205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEnv(gym.Env):\n",
    "    \"\"\"Custom Environment that follows gym interface\"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, grid_size=(10,10),nspecies=255):\n",
    "        super(CustomEnv, self).__init__()\n",
    "        \n",
    "        self.grid_size = grid_size\n",
    "        self.nspecies = nspecies\n",
    "        assert nspecies < 256\n",
    "        nx,ny = grid_size\n",
    "        \n",
    "        # Define action space\n",
    "        self.action_space = spaces.Box(low=np.array([0,0,0]),\n",
    "                                      high=np.array([nx,ny,nspecies]),\n",
    "                                      shape=(3,))        \n",
    "        # Define observation space\n",
    "        self.observation_space = spaces.Box(low=0,\n",
    "                                            high=self.nspecies,\n",
    "                                            shape=grid_size, dtype=np.uint8)\n",
    "        \n",
    "        self._state = np.zeros((10,10))\n",
    "        self.done = False\n",
    "\n",
    "    def step(self, action):       \n",
    "        if self._state[action] != 0 :\n",
    "            reward = -1 #--------> penalty already filled\n",
    "        \n",
    "        self._state[action] = 1\n",
    "        \n",
    "        reward = 1\n",
    "        \n",
    "        info={}\n",
    "        \n",
    "        return np.array([self._state]).astype(np.uint8), reward, done, info\n",
    "        \n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "        return observation, reward, done, info\n",
    "    \n",
    "    def reset(self):\n",
    "         observation = self._state.copy()\n",
    "        return observation\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        ...\n",
    "    def close (self):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4854cd0f-9ec8-4759-ae3c-107d8ade040d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d8e000-a3e3-40ab-a7df-46bbcd7293dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the env\n",
    "env = CustomEnv(arg1, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6679a7a5-a0ec-443f-8f36-def1a7d5b0e7",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9204df5d-b3e2-4cf1-a5c8-25ef63a9a0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = A2C(MlpPolicy, env, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999c225c-5193-45e2-8b74-77ce4f36dccd",
   "metadata": {},
   "source": [
    "Evaluate random Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a269e3f-3494-47bd-ae81-a18648ef096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a separate environement for evaluation\n",
    "eval_env = CustomEnv(arg1, ...)\n",
    "\n",
    "# Random Agent, before training\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=100)\n",
    "\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35099588-4b64-4539-acc6-ef5b6bb1fd84",
   "metadata": {},
   "source": [
    "Train the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0f6ba6-8938-430d-b4d2-d07159629ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the agent for 10000 steps\n",
    "model.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb921820-fd85-4cfa-b383-259727d71322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained agent\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=100)\n",
    "\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ca0ac4-d6d2-47fc-a085-fd9e05dd762f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67b0ea8-5fc0-4f86-8b35-b81819765ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3684b93-71f8-4036-894e-c0aeb902ec5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be867503-ca6f-4619-b08b-ec231742823b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "845100fc-e34d-41e4-b9c1-109938a543d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = (10,10)\n",
    "nx,ny = grid_size\n",
    "nspecies = 255\n",
    "\n",
    "\n",
    "# Define observation space with shape = X, Y, Channel\n",
    "observation = spaces.Box(low=0,\n",
    "                                high=nspecies,\n",
    "                                shape=grid_size, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f8862fa-6223-4b19-89b9-085aa2c5ef1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexkocev/.pyenv/versions/3.8.12/envs/iarchitect/lib/python3.8/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    }
   ],
   "source": [
    "action_space = spaces.Box(low=np.array([0,0,0]),\n",
    "                              high=np.array([nx,ny,nspecies]),\n",
    "                              shape=(3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c73371c-6722-4e96-aa22-7dd4c137b5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d7e40d58-94f1-4def-a907-e724889ebe44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([0. 0. 0.], [ 10.  10. 255.], (3,), float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c03dfee-2897-49a0-acb6-d1e2119ac95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.zeros((10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a590d1fb-1e82-4226-bcb8-5f67c71e8004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d361fba-f000-45f3-9656-b9b89f34af3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction_space\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "state[action_space]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195cb709-1922-4d1b-9712-7f92476a0e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcd32f6-73f4-49e6-9980-124f0384b38a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb13540-f25c-42a8-8af5-5163a0aac168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e26dddb-e1e6-4242-904b-1e1e3d59fedf",
   "metadata": {},
   "source": [
    "## Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acdf2b5-db94-484e-9d95-41d40b060125",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tuile:\n",
    "    def __init__(self, action):\n",
    "        # veg : price, productivity, capacity\n",
    "        self.SCORE = {1:[10,1,1], 2:[8,1,1], 3:[5,1,1], 4:[2,1,1], 5:[6,1,1]}, \n",
    "        self.NEMESIS = {1:[], 2:[1,5], 3:[], 4:[3], 5:[]}\n",
    "        self.rewards = {'PENALTY_NEMESIS':-5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ba822d-5aa6-4ef1-8277-5d4b7a82c90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def affinity(self): \n",
    "\n",
    "        x = action_[0]\n",
    "        y = action_[1]\n",
    "        \n",
    "        if y-1 >=0:\n",
    "            north = self._state[x, y-1]\n",
    "        north = None\n",
    "        if x+1 >=0 and y-1 >=0:\n",
    "            north_east = self._state[x+1, y-1]\n",
    "        north_east = None\n",
    "        if x+1 >=0:\n",
    "            east = self._state[x+1, y]\n",
    "        east = None\n",
    "        if x+1 >=0 and y+1 >=0:\n",
    "            south_east = self._state[x+1, y+1]\n",
    "        south_east = None\n",
    "        if y+1 >= 0:\n",
    "            south = self._state[x, y+1]\n",
    "        south = None\n",
    "        if x-1 >=0 and y+1 >=0:\n",
    "            south_west = self._state[x-1, y+1]  \n",
    "        south_west = None\n",
    "        if x-1 >=0:\n",
    "            west = self._state[x-1, y]\n",
    "        west = None\n",
    "        if x-1 >=0 and y-1 >=0:\n",
    "            north_west = self._state[x-1, y-1]\n",
    "        north_west = None\n",
    "                                          \n",
    "        for nem in self.NEMESIS[action_[2]]:\n",
    "            if nem in [north, north_east, east, south_east,\n",
    "                       south, south_west, west, north_west]:\n",
    "                reward = self.rewards['penalty_nemesis']\n",
    "        \n",
    "    def revenue(self):\n",
    "        for key, value in self.SCORE.items() :\n",
    "            if key == action_[2]:\n",
    "                reward = self.rewards['new_value'] + value[0]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf54075-8e57-424d-ab7b-f20a418528bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858ef87d-2520-4f01-aa32-154f957cd2c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
