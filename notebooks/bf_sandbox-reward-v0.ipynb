{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd11ce82",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb780b98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T16:24:06.325962Z",
     "start_time": "2022-03-03T16:24:04.283725Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 19:02:12.624286: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-03 19:02:12.624339: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tf_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d1556ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T16:24:06.330571Z",
     "start_time": "2022-03-03T16:24:06.326777Z"
    }
   },
   "outputs": [],
   "source": [
    "from tf_agents.agents import DdpgAgent\n",
    "from tf_agents.agents import ddpg\n",
    "\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import tf_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.environments import wrappers\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.metrics import py_metrics\n",
    "from tf_agents.drivers import py_driver,dynamic_episode_driver,dynamic_step_driver\n",
    "from tf_agents.policies import random_py_policy,random_tf_policy,PyTFEagerPolicy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer,py_uniform_replay_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db38d003",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T16:24:06.681945Z",
     "start_time": "2022-03-03T16:24:06.332541Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import base64\n",
    "# import imageio\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "# import pyvirtualdisplay\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import py_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import reverb_replay_buffer\n",
    "from tf_agents.replay_buffers import reverb_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.utils import common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094917ed",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3938c731",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T16:24:06.684896Z",
     "start_time": "2022-03-03T16:24:06.682827Z"
    }
   },
   "outputs": [],
   "source": [
    "# from Maxime\n",
    "nb_actions = 10\n",
    "replay_buffer_capacity = 1000\n",
    "log_interval=100\n",
    "eval_interval=1000\n",
    "\n",
    "# from DQN Tutorial\n",
    "num_iterations = 20000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 100  # @param {type:\"integer\"}\n",
    "collect_steps_per_iteration = 1# @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 200  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 1000  # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a552c3",
   "metadata": {},
   "source": [
    "## Environement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "981b7925",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T16:24:06.687793Z",
     "start_time": "2022-03-03T16:24:06.685742Z"
    }
   },
   "outputs": [],
   "source": [
    "# Input des quotas à produire\n",
    "\n",
    "quota_laitue = 3\n",
    "quota_carotte = 2\n",
    "quota_broccoli = 0\n",
    "quota_tomate = 1\n",
    "quota_chou = 1\n",
    "quota_haricot = 0\n",
    "quota_patate = 4\n",
    "quota_ail = 3\n",
    "quota_oignon = 0\n",
    "quota_courgette = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "522df267",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T16:24:06.695274Z",
     "start_time": "2022-03-03T16:24:06.688611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: ['tomate', 4, 3, 1],\n",
       " 2: ['carotte', 2, 5, 2],\n",
       " 3: ['broccoli', 6, 1, 0],\n",
       " 4: ['chou', 3, 3, 1],\n",
       " 5: ['laitue', 2, 1, 3],\n",
       " 6: ['haricot', 6, 2, 0],\n",
       " 7: ['patate', 2, 4, 4],\n",
       " 8: ['ail', 8, 1, 3],\n",
       " 9: ['oignon', 8, 1, 0],\n",
       " 10: ['courgette', 1, 2, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Définir l'ensemble des tuiles name = [id, prix, rendement, quota]\n",
    "\n",
    "ensemble_des_tuiles = dict()\n",
    "\n",
    "ensemble_des_tuiles[1] = ['tomate',4,3,quota_tomate]\n",
    "ensemble_des_tuiles[2] = ['carotte',2,5,quota_carotte]\n",
    "ensemble_des_tuiles[3] = ['broccoli',6,1,quota_broccoli]\n",
    "ensemble_des_tuiles[4] = ['chou',3,3,quota_chou]\n",
    "ensemble_des_tuiles[5] = ['laitue',2,1,quota_laitue]\n",
    "ensemble_des_tuiles[6] = ['haricot',6,2,quota_haricot]\n",
    "ensemble_des_tuiles[7] = ['patate',2,4,quota_patate]\n",
    "ensemble_des_tuiles[8] = ['ail',8,1,quota_ail]\n",
    "ensemble_des_tuiles[9] = ['oignon',8,1,quota_oignon]\n",
    "ensemble_des_tuiles[10] = ['courgette',1,2,quota_courgette]\n",
    "\n",
    "nb_ensemble_des_tuiles = len(ensemble_des_tuiles)\n",
    "print(nb_ensemble_des_tuiles)\n",
    "ensemble_des_tuiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c73937e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T16:24:06.699583Z",
     "start_time": "2022-03-03T16:24:06.696200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3, 5, 1, 3, 1, 2, 4, 1, 1, 2], [1, 2, 0, 1, 3, 0, 4, 3, 0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Définir l'ensemble des rewards et des quotas\n",
    "\n",
    "ensemble_des_rewards = []\n",
    "ensemble_des_quotas = []\n",
    "\n",
    "for k,v in ensemble_des_tuiles.items():\n",
    "    ensemble_des_rewards.append(v[2])\n",
    "    \n",
    "for k,v in ensemble_des_tuiles.items():\n",
    "    ensemble_des_quotas.append(v[-1])\n",
    "    \n",
    "ensemble_des_rewards, ensemble_des_quotas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b27b7646",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T16:24:06.710664Z",
     "start_time": "2022-03-03T16:24:06.700360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: [0, 0, 1],\n",
       " 1: [0, 0, 2],\n",
       " 2: [0, 0, 3],\n",
       " 3: [0, 0, 4],\n",
       " 4: [0, 0, 5],\n",
       " 5: [0, 0, 6],\n",
       " 6: [0, 0, 7],\n",
       " 7: [0, 0, 8],\n",
       " 8: [0, 0, 9],\n",
       " 9: [0, 0, 10],\n",
       " 10: [1, 0, 1],\n",
       " 11: [1, 0, 2],\n",
       " 12: [1, 0, 3],\n",
       " 13: [1, 0, 4],\n",
       " 14: [1, 0, 5],\n",
       " 15: [1, 0, 6],\n",
       " 16: [1, 0, 7],\n",
       " 17: [1, 0, 8],\n",
       " 18: [1, 0, 9],\n",
       " 19: [1, 0, 10],\n",
       " 20: [2, 0, 1],\n",
       " 21: [2, 0, 2],\n",
       " 22: [2, 0, 3],\n",
       " 23: [2, 0, 4],\n",
       " 24: [2, 0, 5],\n",
       " 25: [2, 0, 6],\n",
       " 26: [2, 0, 7],\n",
       " 27: [2, 0, 8],\n",
       " 28: [2, 0, 9],\n",
       " 29: [2, 0, 10],\n",
       " 30: [3, 0, 1],\n",
       " 31: [3, 0, 2],\n",
       " 32: [3, 0, 3],\n",
       " 33: [3, 0, 4],\n",
       " 34: [3, 0, 5],\n",
       " 35: [3, 0, 6],\n",
       " 36: [3, 0, 7],\n",
       " 37: [3, 0, 8],\n",
       " 38: [3, 0, 9],\n",
       " 39: [3, 0, 10],\n",
       " 40: [4, 0, 1],\n",
       " 41: [4, 0, 2],\n",
       " 42: [4, 0, 3],\n",
       " 43: [4, 0, 4],\n",
       " 44: [4, 0, 5],\n",
       " 45: [4, 0, 6],\n",
       " 46: [4, 0, 7],\n",
       " 47: [4, 0, 8],\n",
       " 48: [4, 0, 9],\n",
       " 49: [4, 0, 10],\n",
       " 50: [5, 0, 1],\n",
       " 51: [5, 0, 2],\n",
       " 52: [5, 0, 3],\n",
       " 53: [5, 0, 4],\n",
       " 54: [5, 0, 5],\n",
       " 55: [5, 0, 6],\n",
       " 56: [5, 0, 7],\n",
       " 57: [5, 0, 8],\n",
       " 58: [5, 0, 9],\n",
       " 59: [5, 0, 10],\n",
       " 60: [6, 0, 1],\n",
       " 61: [6, 0, 2],\n",
       " 62: [6, 0, 3],\n",
       " 63: [6, 0, 4],\n",
       " 64: [6, 0, 5],\n",
       " 65: [6, 0, 6],\n",
       " 66: [6, 0, 7],\n",
       " 67: [6, 0, 8],\n",
       " 68: [6, 0, 9],\n",
       " 69: [6, 0, 10],\n",
       " 70: [7, 0, 1],\n",
       " 71: [7, 0, 2],\n",
       " 72: [7, 0, 3],\n",
       " 73: [7, 0, 4],\n",
       " 74: [7, 0, 5],\n",
       " 75: [7, 0, 6],\n",
       " 76: [7, 0, 7],\n",
       " 77: [7, 0, 8],\n",
       " 78: [7, 0, 9],\n",
       " 79: [7, 0, 10],\n",
       " 80: [8, 0, 1],\n",
       " 81: [8, 0, 2],\n",
       " 82: [8, 0, 3],\n",
       " 83: [8, 0, 4],\n",
       " 84: [8, 0, 5],\n",
       " 85: [8, 0, 6],\n",
       " 86: [8, 0, 7],\n",
       " 87: [8, 0, 8],\n",
       " 88: [8, 0, 9],\n",
       " 89: [8, 0, 10],\n",
       " 90: [9, 0, 1],\n",
       " 91: [9, 0, 2],\n",
       " 92: [9, 0, 3],\n",
       " 93: [9, 0, 4],\n",
       " 94: [9, 0, 5],\n",
       " 95: [9, 0, 6],\n",
       " 96: [9, 0, 7],\n",
       " 97: [9, 0, 8],\n",
       " 98: [9, 0, 9],\n",
       " 99: [9, 0, 10],\n",
       " 100: [10, 0, 1],\n",
       " 101: [10, 0, 2],\n",
       " 102: [10, 0, 3],\n",
       " 103: [10, 0, 4],\n",
       " 104: [10, 0, 5],\n",
       " 105: [10, 0, 6],\n",
       " 106: [10, 0, 7],\n",
       " 107: [10, 0, 8],\n",
       " 108: [10, 0, 9],\n",
       " 109: [10, 0, 10],\n",
       " 110: [11, 0, 1],\n",
       " 111: [11, 0, 2],\n",
       " 112: [11, 0, 3],\n",
       " 113: [11, 0, 4],\n",
       " 114: [11, 0, 5],\n",
       " 115: [11, 0, 6],\n",
       " 116: [11, 0, 7],\n",
       " 117: [11, 0, 8],\n",
       " 118: [11, 0, 9],\n",
       " 119: [11, 0, 10],\n",
       " 120: [12, 0, 1],\n",
       " 121: [12, 0, 2],\n",
       " 122: [12, 0, 3],\n",
       " 123: [12, 0, 4],\n",
       " 124: [12, 0, 5],\n",
       " 125: [12, 0, 6],\n",
       " 126: [12, 0, 7],\n",
       " 127: [12, 0, 8],\n",
       " 128: [12, 0, 9],\n",
       " 129: [12, 0, 10],\n",
       " 130: [13, 0, 1],\n",
       " 131: [13, 0, 2],\n",
       " 132: [13, 0, 3],\n",
       " 133: [13, 0, 4],\n",
       " 134: [13, 0, 5],\n",
       " 135: [13, 0, 6],\n",
       " 136: [13, 0, 7],\n",
       " 137: [13, 0, 8],\n",
       " 138: [13, 0, 9],\n",
       " 139: [13, 0, 10],\n",
       " 140: [14, 0, 1],\n",
       " 141: [14, 0, 2],\n",
       " 142: [14, 0, 3],\n",
       " 143: [14, 0, 4],\n",
       " 144: [14, 0, 5],\n",
       " 145: [14, 0, 6],\n",
       " 146: [14, 0, 7],\n",
       " 147: [14, 0, 8],\n",
       " 148: [14, 0, 9],\n",
       " 149: [14, 0, 10],\n",
       " 150: [15, 0, 1],\n",
       " 151: [15, 0, 2],\n",
       " 152: [15, 0, 3],\n",
       " 153: [15, 0, 4],\n",
       " 154: [15, 0, 5],\n",
       " 155: [15, 0, 6],\n",
       " 156: [15, 0, 7],\n",
       " 157: [15, 0, 8],\n",
       " 158: [15, 0, 9],\n",
       " 159: [15, 0, 10],\n",
       " 160: [16, 0, 1],\n",
       " 161: [16, 0, 2],\n",
       " 162: [16, 0, 3],\n",
       " 163: [16, 0, 4],\n",
       " 164: [16, 0, 5],\n",
       " 165: [16, 0, 6],\n",
       " 166: [16, 0, 7],\n",
       " 167: [16, 0, 8],\n",
       " 168: [16, 0, 9],\n",
       " 169: [16, 0, 10],\n",
       " 170: [17, 0, 1],\n",
       " 171: [17, 0, 2],\n",
       " 172: [17, 0, 3],\n",
       " 173: [17, 0, 4],\n",
       " 174: [17, 0, 5],\n",
       " 175: [17, 0, 6],\n",
       " 176: [17, 0, 7],\n",
       " 177: [17, 0, 8],\n",
       " 178: [17, 0, 9],\n",
       " 179: [17, 0, 10],\n",
       " 180: [18, 0, 1],\n",
       " 181: [18, 0, 2],\n",
       " 182: [18, 0, 3],\n",
       " 183: [18, 0, 4],\n",
       " 184: [18, 0, 5],\n",
       " 185: [18, 0, 6],\n",
       " 186: [18, 0, 7],\n",
       " 187: [18, 0, 8],\n",
       " 188: [18, 0, 9],\n",
       " 189: [18, 0, 10],\n",
       " 190: [19, 0, 1],\n",
       " 191: [19, 0, 2],\n",
       " 192: [19, 0, 3],\n",
       " 193: [19, 0, 4],\n",
       " 194: [19, 0, 5],\n",
       " 195: [19, 0, 6],\n",
       " 196: [19, 0, 7],\n",
       " 197: [19, 0, 8],\n",
       " 198: [19, 0, 9],\n",
       " 199: [19, 0, 10],\n",
       " 200: [20, 0, 1],\n",
       " 201: [20, 0, 2],\n",
       " 202: [20, 0, 3],\n",
       " 203: [20, 0, 4],\n",
       " 204: [20, 0, 5],\n",
       " 205: [20, 0, 6],\n",
       " 206: [20, 0, 7],\n",
       " 207: [20, 0, 8],\n",
       " 208: [20, 0, 9],\n",
       " 209: [20, 0, 10],\n",
       " 210: [21, 0, 1],\n",
       " 211: [21, 0, 2],\n",
       " 212: [21, 0, 3],\n",
       " 213: [21, 0, 4],\n",
       " 214: [21, 0, 5],\n",
       " 215: [21, 0, 6],\n",
       " 216: [21, 0, 7],\n",
       " 217: [21, 0, 8],\n",
       " 218: [21, 0, 9],\n",
       " 219: [21, 0, 10],\n",
       " 220: [22, 0, 1],\n",
       " 221: [22, 0, 2],\n",
       " 222: [22, 0, 3],\n",
       " 223: [22, 0, 4],\n",
       " 224: [22, 0, 5],\n",
       " 225: [22, 0, 6],\n",
       " 226: [22, 0, 7],\n",
       " 227: [22, 0, 8],\n",
       " 228: [22, 0, 9],\n",
       " 229: [22, 0, 10],\n",
       " 230: [23, 0, 1],\n",
       " 231: [23, 0, 2],\n",
       " 232: [23, 0, 3],\n",
       " 233: [23, 0, 4],\n",
       " 234: [23, 0, 5],\n",
       " 235: [23, 0, 6],\n",
       " 236: [23, 0, 7],\n",
       " 237: [23, 0, 8],\n",
       " 238: [23, 0, 9],\n",
       " 239: [23, 0, 10],\n",
       " 240: [24, 0, 1],\n",
       " 241: [24, 0, 2],\n",
       " 242: [24, 0, 3],\n",
       " 243: [24, 0, 4],\n",
       " 244: [24, 0, 5],\n",
       " 245: [24, 0, 6],\n",
       " 246: [24, 0, 7],\n",
       " 247: [24, 0, 8],\n",
       " 248: [24, 0, 9],\n",
       " 249: [24, 0, 10]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Définir l'ensemble des actions possibles\n",
    "\n",
    "import itertools\n",
    "\n",
    "nb_tuiles = nb_ensemble_des_tuiles\n",
    "dim_x = 25\n",
    "dim_y = 1\n",
    "ensemble_des_possibles = dict()\n",
    "\n",
    "compteur = -1\n",
    "for x,y,t in itertools.product(range(dim_x),range(dim_y),range(1, nb_tuiles+1)):\n",
    "    compteur += 1\n",
    "    ensemble_des_possibles[compteur] = [x,y,t]\n",
    "    \n",
    "nb_ensemble_des_possibles = len(ensemble_des_possibles)\n",
    "print(nb_ensemble_des_possibles)\n",
    "ensemble_des_possibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d1accd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T16:32:34.050232Z",
     "start_time": "2022-03-03T16:32:34.006120Z"
    }
   },
   "outputs": [],
   "source": [
    "class IArchitectEnv(py_environment.PyEnvironment):\n",
    "    def __init__(self,verbose=False):\n",
    "        # Initialisation environment\n",
    "        self._state = np.zeros((dim_x,),dtype=np.int32)\n",
    "        self._action_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(), dtype=np.int32, minimum=0, maximum=nb_ensemble_des_possibles-1, name='action')\n",
    "        self._observation_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(dim_x,), dtype=np.int32, minimum=0, maximum=nb_tuiles, name='observation')\n",
    "        self._episode_ended = False\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Initialisation rewards/quotas\n",
    "        self.REWARD = 1000\n",
    "        self.PENALTY_ALREADY_FILLED = -100\n",
    "        self.DEFAULT_REWARD = ensemble_des_rewards\n",
    "        self.QUOTA = ensemble_des_quotas\n",
    "        self.COUNTER = 0\n",
    "\n",
    "        \n",
    "    def action_spec(self):\n",
    "        return self._action_spec\n",
    "\n",
    "    \n",
    "    def observation_spec(self):\n",
    "        return self._observation_spec\n",
    "\n",
    "    \n",
    "    def _reset(self):\n",
    "        self._state = np.zeros((dim_x,),dtype=np.int32)\n",
    "        self._episode_ended = False\n",
    "        self.COUNTER = 0\n",
    "        return ts.restart(self._state)\n",
    "\n",
    "\n",
    "    def _step(self, action):\n",
    "        \n",
    "        while self.COUNTER <= 20:\n",
    "            \n",
    "            x, y, t = ensemble_des_possibles[int(action)]\n",
    "            \n",
    "            unique, counts = np.unique(self._state, return_counts=True)\n",
    "            quota_en_cours = dict(zip(unique, counts))\n",
    "            quota_a_faire = self.QUOTA\n",
    "            reward_policy = self.DEFAULT_REWARD\n",
    "            quota_restant = []\n",
    "        \n",
    "            for i in quota_a_faire:\n",
    "                quota_restant.append(quota_a_faire[i] - quota_en_cours.get(i,0))\n",
    "        \n",
    "        \n",
    "            if self._episode_ended:\n",
    "                return self.reset()\n",
    "\n",
    "            if self.verbose:\n",
    "                print(self._state,action,x,y,t)\n",
    "\n",
    "            # Définition de la reward par défaut\n",
    "            reward = 1\n",
    "\n",
    "            # Analyse des conditions de défaite\n",
    "            if self._state[x] > 0: # Contrôler la défaite\n",
    "                reward = self.PENALTY_ALREADY_FILLED\n",
    "            \n",
    "            self._state[x] = t # Définition de l'action\n",
    "            \n",
    "            # Définition de la reward\n",
    "            if sum(1 for number in quota_restant if number<=0)==len(quota_restant):\n",
    "                reward = reward_policy[t-1]/2\n",
    "            else:\n",
    "                reward = reward_policy[t-1]*2\n",
    "                \n",
    "# Contrôler la victoire\n",
    "        # Analyse des conditions de victoire\n",
    "            if 0 not in self._state:\n",
    "                self._episode_ended = True\n",
    "                reward = self.REWARD\n",
    "        \n",
    "            if not self._episode_ended:\n",
    "                result = ts.transition(self._state, reward=reward, discount=1.0)\n",
    "            else:\n",
    "                result = ts.termination(self._state, reward=reward)\n",
    "        \n",
    "            if self.verbose:\n",
    "                print(result.observation,reward)\n",
    "                \n",
    "            self.COUNTER += 1\n",
    "            \n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cda20ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T16:32:34.332698Z",
     "start_time": "2022-03-03T16:32:34.270466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] 203 20 0 4\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0] 6\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0] 97 9 0 8\n",
      "[0 0 0 0 0 0 0 0 0 8 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0] 2\n",
      "[0 0 0 0 0 0 0 0 0 8 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0] 8 0 0 9\n",
      "[9 0 0 0 0 0 0 0 0 8 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0] 2\n",
      "[9 0 0 0 0 0 0 0 0 8 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0] 134 13 0 5\n",
      "[9 0 0 0 0 0 0 0 0 8 0 0 0 5 0 0 0 0 0 0 4 0 0 0 0] 2\n",
      "[9 0 0 0 0 0 0 0 0 8 0 0 0 5 0 0 0 0 0 0 4 0 0 0 0] 76 7 0 7\n",
      "[9 0 0 0 0 0 0 7 0 8 0 0 0 5 0 0 0 0 0 0 4 0 0 0 0] 8\n",
      "[9 0 0 0 0 0 0 7 0 8 0 0 0 5 0 0 0 0 0 0 4 0 0 0 0] 86 8 0 7\n",
      "[9 0 0 0 0 0 0 7 7 8 0 0 0 5 0 0 0 0 0 0 4 0 0 0 0] 8\n",
      "[9 0 0 0 0 0 0 7 7 8 0 0 0 5 0 0 0 0 0 0 4 0 0 0 0] 71 7 0 2\n",
      "[9 0 0 0 0 0 0 2 7 8 0 0 0 5 0 0 0 0 0 0 4 0 0 0 0] 10\n",
      "[9 0 0 0 0 0 0 2 7 8 0 0 0 5 0 0 0 0 0 0 4 0 0 0 0] 117 11 0 8\n",
      "[9 0 0 0 0 0 0 2 7 8 0 8 0 5 0 0 0 0 0 0 4 0 0 0 0] 2\n",
      "[9 0 0 0 0 0 0 2 7 8 0 8 0 5 0 0 0 0 0 0 4 0 0 0 0] 22 2 0 3\n",
      "[9 0 3 0 0 0 0 2 7 8 0 8 0 5 0 0 0 0 0 0 4 0 0 0 0] 2\n",
      "[9 0 3 0 0 0 0 2 7 8 0 8 0 5 0 0 0 0 0 0 4 0 0 0 0] 45 4 0 6\n",
      "[9 0 3 0 6 0 0 2 7 8 0 8 0 5 0 0 0 0 0 0 4 0 0 0 0] 4\n",
      "[9 0 3 0 6 0 0 2 7 8 0 8 0 5 0 0 0 0 0 0 4 0 0 0 0] 84 8 0 5\n",
      "[9 0 3 0 6 0 0 2 5 8 0 8 0 5 0 0 0 0 0 0 4 0 0 0 0] 2\n",
      "[9 0 3 0 6 0 0 2 5 8 0 8 0 5 0 0 0 0 0 0 4 0 0 0 0] 70 7 0 1\n",
      "[9 0 3 0 6 0 0 1 5 8 0 8 0 5 0 0 0 0 0 0 4 0 0 0 0] 6\n",
      "[9 0 3 0 6 0 0 1 5 8 0 8 0 5 0 0 0 0 0 0 4 0 0 0 0] 198 19 0 9\n",
      "[9 0 3 0 6 0 0 1 5 8 0 8 0 5 0 0 0 0 0 9 4 0 0 0 0] 2\n",
      "[9 0 3 0 6 0 0 1 5 8 0 8 0 5 0 0 0 0 0 9 4 0 0 0 0] 34 3 0 5\n",
      "[9 0 3 5 6 0 0 1 5 8 0 8 0 5 0 0 0 0 0 9 4 0 0 0 0] 2\n",
      "[9 0 3 5 6 0 0 1 5 8 0 8 0 5 0 0 0 0 0 9 4 0 0 0 0] 31 3 0 2\n",
      "[9 0 3 2 6 0 0 1 5 8 0 8 0 5 0 0 0 0 0 9 4 0 0 0 0] 10\n",
      "[9 0 3 2 6 0 0 1 5 8 0 8 0 5 0 0 0 0 0 9 4 0 0 0 0] 231 23 0 2\n",
      "[9 0 3 2 6 0 0 1 5 8 0 8 0 5 0 0 0 0 0 9 4 0 0 2 0] 10\n",
      "[9 0 3 2 6 0 0 1 5 8 0 8 0 5 0 0 0 0 0 9 4 0 0 2 0] 139 13 0 10\n",
      "[ 9  0  3  2  6  0  0  1  5  8  0  8  0 10  0  0  0  0  0  9  4  0  0  2\n",
      "  0] 4\n",
      "[ 9  0  3  2  6  0  0  1  5  8  0  8  0 10  0  0  0  0  0  9  4  0  0  2\n",
      "  0] 137 13 0 8\n",
      "[9 0 3 2 6 0 0 1 5 8 0 8 0 8 0 0 0 0 0 9 4 0 0 2 0] 2\n",
      "[9 0 3 2 6 0 0 1 5 8 0 8 0 8 0 0 0 0 0 9 4 0 0 2 0] 135 13 0 6\n",
      "[9 0 3 2 6 0 0 1 5 8 0 8 0 6 0 0 0 0 0 9 4 0 0 2 0] 4\n",
      "[9 0 3 2 6 0 0 1 5 8 0 8 0 6 0 0 0 0 0 9 4 0 0 2 0] 228 22 0 9\n",
      "[9 0 3 2 6 0 0 1 5 8 0 8 0 6 0 0 0 0 0 9 4 0 9 2 0] 2\n",
      "[9 0 3 2 6 0 0 1 5 8 0 8 0 6 0 0 0 0 0 9 4 0 9 2 0] 116 11 0 7\n",
      "[9 0 3 2 6 0 0 1 5 8 0 7 0 6 0 0 0 0 0 9 4 0 9 2 0] 8\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'is_last'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m train_env \u001b[38;5;241m=\u001b[39m tf_py_environment\u001b[38;5;241m.\u001b[39mTFPyEnvironment(environment)\n\u001b[1;32m      4\u001b[0m eval_env \u001b[38;5;241m=\u001b[39m tf_py_environment\u001b[38;5;241m.\u001b[39mTFPyEnvironment(environment)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_py_environment\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/iarchitect/lib/python3.8/site-packages/tf_agents/environments/utils.py:85\u001b[0m, in \u001b[0;36mvalidate_py_environment\u001b[0;34m(environment, episodes, observation_and_action_constraint_splitter)\u001b[0m\n\u001b[1;32m     82\u001b[0m action \u001b[38;5;241m=\u001b[39m random_policy\u001b[38;5;241m.\u001b[39maction(time_step)\u001b[38;5;241m.\u001b[39maction\n\u001b[1;32m     83\u001b[0m time_step \u001b[38;5;241m=\u001b[39m environment\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m---> 85\u001b[0m episode_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[43mtime_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_last\u001b[49m())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'is_last'"
     ]
    }
   ],
   "source": [
    "# Initialiser les environnement\n",
    "environment = IArchitectEnv(verbose=True)\n",
    "train_env = tf_py_environment.TFPyEnvironment(environment)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(environment)\n",
    "\n",
    "utils.validate_py_environment(environment, episodes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebf121c",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c1277a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T16:24:07.105851Z",
     "start_time": "2022-03-03T16:24:07.105846Z"
    }
   },
   "outputs": [],
   "source": [
    "fc_layer_params = (200, 100)\n",
    "action_tensor_spec = tensor_spec.from_spec(environment.action_spec())\n",
    "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
    "\n",
    "# Define a helper function to create Dense layers configured with the right\n",
    "# activation and kernel initializer.\n",
    "def dense_layer(num_units):\n",
    "      return tf.keras.layers.Dense(\n",
    "          num_units,\n",
    "          activation=tf.keras.activations.relu,\n",
    "          kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
    "              scale=2.0, mode='fan_in', distribution='truncated_normal'))\n",
    "\n",
    "# QNetwork consists of a sequence of Dense layers followed by a dense layer\n",
    "# with `num_actions` units to generate one q_value per available action as\n",
    "# its output.\n",
    "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
    "q_values_layer = tf.keras.layers.Dense(\n",
    "    num_actions,\n",
    "    activation=None,\n",
    "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
    "        minval=-0.03, maxval=0.03),\n",
    "    bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
    "q_net = sequential.Sequential(dense_layers + [q_values_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6ea628",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T16:24:07.106291Z",
     "start_time": "2022-03-03T16:24:07.106285Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2e0926",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T16:24:07.107088Z",
     "start_time": "2022-03-03T16:24:07.107082Z"
    }
   },
   "outputs": [],
   "source": [
    "q_net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6ef46",
   "metadata": {},
   "source": [
    "## Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7e886f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T16:24:07.107520Z",
     "start_time": "2022-03-03T16:24:07.107514Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8bc9a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T16:24:07.108098Z",
     "start_time": "2022-03-03T16:24:07.108093Z"
    }
   },
   "outputs": [],
   "source": [
    "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
    "                                                train_env.action_spec())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c842b23",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b32dd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T16:24:07.108837Z",
     "start_time": "2022-03-03T16:24:07.108832Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "    total_return = 0.0\n",
    "    for _ in range(num_episodes):\n",
    "\n",
    "        time_step = environment.reset()\n",
    "        episode_return = 0.0\n",
    "\n",
    "        while not time_step.is_last():\n",
    "            action_step = policy.action(time_step)\n",
    "            time_step = environment.step(action_step.action)\n",
    "            episode_return += time_step.reward\n",
    "        total_return += episode_return\n",
    "\n",
    "    avg_return = total_return / num_episodes\n",
    "    return avg_return.numpy()[0]\n",
    "\n",
    "\n",
    "# See also the metrics module for standard implementations of different metrics.\n",
    "# https://github.com/tensorflow/agents/tree/master/tf_agents/metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73a22fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T16:24:07.109409Z",
     "start_time": "2022-03-03T16:24:07.109404Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_return = compute_avg_return(eval_env, random_policy, num_eval_episodes)\n",
    "returns = [avg_return]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3e38b0",
   "metadata": {},
   "source": [
    "## Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e9fa56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T16:24:07.110070Z",
     "start_time": "2022-03-03T16:24:07.110063Z"
    }
   },
   "outputs": [],
   "source": [
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "                                data_spec=agent.collect_data_spec,                                                     \n",
    "                                batch_size=train_env.batch_size,                                                             \n",
    "                                max_length=100000)\n",
    "\n",
    "def collect_step(environment, policy, buffer):\n",
    "    time_step = environment.current_time_step()\n",
    "    action_step = policy.action(time_step)\n",
    "    next_time_step = environment.step(action_step.action)\n",
    "    traj = trajectory.from_transition(time_step, \n",
    "                                      action_step, \n",
    "                                      next_time_step)\n",
    "# Add trajectory to the replay buffer\n",
    "    buffer.add_batch(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a38fbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T16:24:07.110549Z",
     "start_time": "2022-03-03T16:24:07.110543Z"
    }
   },
   "outputs": [],
   "source": [
    "train_env.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7745b70f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T16:24:07.110966Z",
     "start_time": "2022-03-03T16:24:07.110960Z"
    }
   },
   "outputs": [],
   "source": [
    "collect_steps_per_iteration = 1\n",
    "batch_size = 64\n",
    "dataset = replay_buffer.as_dataset(num_parallel_calls=3, \n",
    "                                   sample_batch_size=batch_size, \n",
    "                                   num_steps=2).prefetch(3)\n",
    "iterator = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30900ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T16:24:07.111778Z",
     "start_time": "2022-03-03T16:24:07.111773Z"
    }
   },
   "outputs": [],
   "source": [
    "result_loss = []\n",
    "num_iterations = 20000\n",
    "train_env.reset()\n",
    "for _ in range(batch_size):\n",
    "    collect_step(train_env, agent.policy, replay_buffer)\n",
    "for _ in range(num_iterations):\n",
    "    # Collect a few steps using collect_policy and save to the replay buffer.\n",
    "    for _ in range(collect_steps_per_iteration):\n",
    "        collect_step(train_env, agent.collect_policy, replay_buffer)\n",
    "    # Sample a batch of data from the buffer and update the agent's network.\n",
    "    experience, unused_info = next(iterator)\n",
    "    train_loss = agent.train(experience).loss\n",
    "    step = agent.train_step_counter.numpy()\n",
    "    # Print loss every 200 steps.\n",
    "    if step % 200 == 0:\n",
    "        print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "        result_loss.append(train_loss)\n",
    "    # Evaluate agent's performance every 1000 steps.\n",
    "    if step % 1000 == 0:\n",
    "        avg_return = compute_avg_return(train_env, agent.policy, 5)\n",
    "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "        returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb44ba5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T16:24:07.112510Z",
     "start_time": "2022-03-03T16:24:07.112504Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(result_loss)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999d4af6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T16:24:07.112876Z",
     "start_time": "2022-03-03T16:24:07.112870Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Iterations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa25d358",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eea7435",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T16:24:07.113629Z",
     "start_time": "2022-03-03T16:24:07.113623Z"
    }
   },
   "outputs": [],
   "source": [
    "observers = []\n",
    "driver = py_driver.PyDriver(\n",
    "    eval_env, PyTFEagerPolicy(agent.policy), observers, max_steps=1000, max_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeec5da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T16:24:07.114088Z",
     "start_time": "2022-03-03T16:24:07.114082Z"
    }
   },
   "outputs": [],
   "source": [
    "time_spec_init = eval_env.reset()\n",
    "driver.run(time_spec_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8506f968",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "195px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
